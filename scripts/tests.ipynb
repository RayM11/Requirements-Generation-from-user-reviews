{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T04:55:54.952497300Z",
     "start_time": "2024-12-01T04:55:54.939432300Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from scripts.utils import load_glossary, get_tokenized_glossary\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando el glosario...\n",
      "\n",
      "Glosario Procesado\n",
      "                             Term\n",
      "0                          [2256]\n",
      "1                         [14101]\n",
      "2                         [59587]\n",
      "3                           [883]\n",
      "4                          [8554]\n",
      "...                           ...\n",
      "5606                  [864, 7646]\n",
      "5607   [57012, 5813, 12616, 5807]\n",
      "5608  [57012, 5813, 12616, 13287]\n",
      "5609      [53063, 4069, 20, 1155]\n",
      "5610    [46631, 231, 2923, 21979]\n",
      "\n",
      "[5611 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"../models/BERTweet - base\")\n",
    "glossary = load_glossary()\n",
    "tokenized_glossary = get_tokenized_glossary(tokenizer, glossary)\n",
    "\n",
    "print(tokenized_glossary)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-29T23:33:51.984626600Z",
     "start_time": "2024-11-29T23:33:51.369904700Z"
    }
   },
   "id": "d6dfa1f5bae5fd09"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "comment = \"This is a simple test, a!?= about something. This is a simple test.\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-29T23:35:04.460662400Z",
     "start_time": "2024-11-29T23:35:04.460662400Z"
    }
   },
   "id": "143e597005cea376"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoding = tokenizer.encode_plus(\n",
    "                                comment,\n",
    "                                add_special_tokens=True,\n",
    "                                max_length=130,\n",
    "                                return_token_type_ids=False,\n",
    "                                padding=\"max_length\",\n",
    "                                truncation=True,\n",
    "                                return_attention_mask=True,\n",
    "                                return_tensors='pt'\n",
    "                                )\n",
    "\n",
    "print(encoding[\"input_ids\"].flatten())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "323606e7c79f135a"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'CommentClassifier' on <module 'classes.CommentClassifier' from 'C:\\\\Ray\\\\Repositories\\\\Requeriments-Classifier-with-Transformers\\\\classes\\\\CommentClassifier.py'>",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../models/fine-tuned/comment_relevance_detector (facebook).pth\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m model\u001B[38;5;241m.\u001B[39msave_pretrained(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../models/RoBERTa_relevance_detection\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1026\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[0;32m   1024\u001B[0m             \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1025\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError(UNSAFE_MESSAGE \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(e)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1026\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mopened_zipfile\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1027\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1028\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mpickle_module\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1029\u001B[0m \u001B[43m                     \u001B[49m\u001B[43moverall_storage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moverall_storage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1030\u001B[0m \u001B[43m                     \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpickle_load_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1031\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mmap:\n\u001B[0;32m   1032\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmmap can only be used with files saved with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1033\u001B[0m                        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`torch.save(_use_new_zipfile_serialization=True), \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1034\u001B[0m                        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplease torch.save your checkpoint with this option in order to use mmap.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1438\u001B[0m, in \u001B[0;36m_load\u001B[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001B[0m\n\u001B[0;32m   1436\u001B[0m unpickler \u001B[38;5;241m=\u001B[39m UnpicklerWrapper(data_file, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[0;32m   1437\u001B[0m unpickler\u001B[38;5;241m.\u001B[39mpersistent_load \u001B[38;5;241m=\u001B[39m persistent_load\n\u001B[1;32m-> 1438\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43munpickler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1440\u001B[0m torch\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_validate_loaded_sparse_tensors()\n\u001B[0;32m   1441\u001B[0m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_log_api_usage_metadata(\n\u001B[0;32m   1442\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch.load.metadata\u001B[39m\u001B[38;5;124m\"\u001B[39m, {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mserialization_id\u001B[39m\u001B[38;5;124m\"\u001B[39m: zip_file\u001B[38;5;241m.\u001B[39mserialization_id()}\n\u001B[0;32m   1443\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1431\u001B[0m, in \u001B[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001B[1;34m(self, mod_name, name)\u001B[0m\n\u001B[0;32m   1429\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m   1430\u001B[0m mod_name \u001B[38;5;241m=\u001B[39m load_module_mapping\u001B[38;5;241m.\u001B[39mget(mod_name, mod_name)\n\u001B[1;32m-> 1431\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfind_class\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmod_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mAttributeError\u001B[0m: Can't get attribute 'CommentClassifier' on <module 'classes.CommentClassifier' from 'C:\\\\Ray\\\\Repositories\\\\Requeriments-Classifier-with-Transformers\\\\classes\\\\CommentClassifier.py'>"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"../models/fine-tuned/comment_relevance_detector (facebook).pth\")\n",
    "model.save_pretrained(\"../models/RoBERTa_relevance_detection\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-01T04:56:06.975556100Z",
     "start_time": "2024-12-01T04:56:06.929826700Z"
    }
   },
   "id": "7868bb3d51561472"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "875c6d87a48ddae0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
