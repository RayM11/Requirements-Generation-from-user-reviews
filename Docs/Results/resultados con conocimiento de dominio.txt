Roberta - facebook
---------------------------------------------------------------------------------------------------------------------------------

Linear + RELEVANT_COUNT

Results : [
 {'accuracy': 0.94, 		  'precision': 0.8884297520661157, 'recall': 0.9598214285714286, 'F1-score': 0.9227467811158798},
 {'accuracy': 0.9466666666666667, 'precision': 0.9465648854961832, 'recall': 0.9323308270676691, 'F1-score': 0.9393939393939394},
 {'accuracy': 0.9566666666666667, 'precision': 0.927007299270073,  'recall': 0.9769230769230769, 'F1-score': 0.951310861423221},
 {'accuracy': 0.9183333333333333, 'precision': 0.8671328671328671, 'recall': 0.9575289575289575, 'F1-score': 0.9100917431192661},
 {'accuracy': 0.9433333333333334, 'precision': 0.9562043795620438, 'recall': 0.9225352112676056, 'F1-score': 0.9390681003584228}
]
Avg results:  
 {'accuracy': 0.9410000000000001, 'precision': 0.9170678367054566, 'recall': 0.9498279002717476, 'F1-score': 0.9325222850821457}

Linear + RELEVANT_POSITION

Results : [
 {'accuracy': 0.9333333333333333, 'precision': 0.9669421487603306, 'recall': 0.8796992481203008, 'F1-score': 0.921259842519685},
 {'accuracy': 0.9383333333333334, 'precision': 0.9198473282442748, 'recall': 0.9377431906614786, 'F1-score': 0.9287090558766858},
 {'accuracy': 0.95, 	     	  'precision': 0.9233576642335767, 'recall': 0.9656488549618321, 'F1-score': 0.9440298507462687},
 {'accuracy': 0.885, 		  'precision': 0.7727272727272727, 'recall': 0.9822222222222222, 'F1-score': 0.8649706457925636},
 {'accuracy': 0.9433333333333334, 'precision': 0.927007299270073,  'recall': 0.9477611940298507, 'F1-score': 0.937269372693727}
]
Avg results:  {'accuracy': 0.9299999999999999, 'precision': 0.9019763426471057, 'recall': 0.9426149419991369, 'F1-score': 0.9192477535257859}



MLP + RELEVANT_POSITION

Results : [
 {'accuracy': 0.9383333333333334, 'precision': 0.9504132231404959, 'recall': 0.9019607843137255, 'F1-score': 0.9255533199195172},
 {'accuracy': 0.9216666666666666, 'precision': 0.8931297709923665, 'recall': 0.924901185770751,  'F1-score': 0.9087378640776699},
 {'accuracy': 0.95, 		  'precision': 0.9306569343065694, 'recall': 0.9586466165413534, 'F1-score': 0.9444444444444444},
 {'accuracy': 0.925, 		  'precision': 0.8916083916083916, 'recall': 0.9479553903345725, 'F1-score': 0.9189189189189187},
 {'accuracy': 0.9266666666666666, 'precision': 0.9562043795620438, 'recall': 0.891156462585034,  'F1-score': 0.9225352112676056}
]
Avg results: 
 {'accuracy': 0.9323333333333332, 'precision': 0.9244025399219735, 'recall': 0.9249240879090873, 'F1-score': 0.9240379517256312}

MLP + RELEVANT_COUNT

Results : [
 {'accuracy': 0.9016666666666666, 'precision': 0.9545454545454546, 'recall': 0.8279569892473119, 'F1-score': 0.8867562380038386},
 {'accuracy': 0.94, 		  'precision': 0.950381679389313,  'recall': 0.9154411764705882, 'F1-score': 0.9325842696629214},
 {'accuracy': 0.9516666666666667, 'precision': 0.9343065693430657, 'recall': 0.9588014981273408, 'F1-score': 0.9463955637707949},
 {'accuracy': 0.93, 		  'precision': 0.8916083916083916, 'recall': 0.9586466165413534, 'F1-score': 0.9239130434782608},
 {'accuracy': 0.9316666666666666, 'precision': 0.9744525547445255, 'recall': 0.8870431893687708, 'F1-score': 0.928695652173913}
]
Avg results:  
 {'accuracy': 0.9309999999999998, 'precision': 0.94105892992615,   'recall': 0.909577893951073, 'F1-score': 0.9236689534179459}



BERTweet - Facebook
-------------------------------------------------------------------------------------------------------------------------------------
Linear + RP

Results : [
 {'accuracy': 0.935, 		  'precision': 0.8801652892561983, 'recall': 0.9551569506726457, 'F1-score': 0.9161290322580644},
 {'accuracy': 0.9266666666666666, 'precision': 0.950381679389313,  'recall': 0.8892857142857142, 'F1-score': 0.918819188191882},
 {'accuracy': 0.9433333333333334, 'precision': 0.8978102189781022, 'recall': 0.9761904761904762, 'F1-score': 0.935361216730038},
 {'accuracy': 0.9233333333333333, 'precision': 0.9825174825174825, 'recall': 0.8726708074534162, 'F1-score': 0.924342105263158},
 {'accuracy': 0.9366666666666666, 'precision': 0.9562043795620438, 'recall': 0.9097222222222222, 'F1-score': 0.9323843416370107}
]
Avg results: 
 {'accuracy': 0.933, 'precision': 0.9334158099406279, 'recall': 0.9206052341648949, 'F1-score': 0.9254071768160307}


Linear + RC

Results : [
 {'accuracy': 0.9516666666666667, 'precision': 0.9214876033057852, 'recall': 0.9570815450643777, 'F1-score': 0.9389473684210525},
 {'accuracy': 0.94, 		  'precision': 0.9236641221374046, 'recall': 0.937984496124031,  'F1-score': 0.9307692307692308},
 {'accuracy': 0.9416666666666667, 'precision': 0.9087591240875912, 'recall': 0.9613899613899614, 'F1-score': 0.9343339587242026},
 {'accuracy': 0.9366666666666666, 'precision': 0.9020979020979021, 'recall': 0.9626865671641791, 'F1-score': 0.9314079422382672},
 {'accuracy': 0.94, 		  'precision': 0.9233576642335767, 'recall': 0.9440298507462687, 'F1-score': 0.933579335793358}
]
Avg results: 
 {'accuracy': 0.9419999999999998, 'precision': 0.9158732831724519, 'recall': 0.9526344840977636, 'F1-score': 0.9338075671892222}


MLP + RC

Results : [
 {'accuracy': 0.9433333333333334, 'precision': 0.9462809917355371, 'recall': 0.916, 		 'F1-score': 0.9308943089430893},
 {'accuracy': 0.925, 		  'precision': 0.9427480916030534, 'recall': 0.8916967509025271, 'F1-score': 0.9165120593692022},
 {'accuracy': 0.9466666666666667, 'precision': 0.9197080291970803, 'recall': 0.9618320610687023, 'F1-score': 0.9402985074626865},
 {'accuracy': 0.915, 		  'precision': 0.9335664335664335, 'recall': 0.8929765886287625, 'F1-score': 0.9128205128205128},
 {'accuracy': 0.94,	          'precision': 0.9233576642335767, 'recall': 0.9440298507462687, 'F1-score': 0.933579335793358}
]
Avg results: 
 {'accuracy': 0.9339999999999999, 'precision': 0.9331322420671363, 'recall': 0.9213070502692522, 'F1-score': 0.9268209448777697}



MLP + RP

Results : [
 {'accuracy': 0.9383333333333334, 'precision': 0.9008264462809917, 'recall': 0.9437229437229437, 'F1-score': 0.9217758985200846},
 {'accuracy': 0.9183333333333333, 'precision': 0.8473282442748091, 'recall': 0.961038961038961,  'F1-score': 0.900608519269777},
 {'accuracy': 0.92, 		  'precision': 0.8467153284671532, 'recall': 0.9747899159663865, 'F1-score': 0.9062500000000001},
 {'accuracy': 0.9116666666666666, 'precision': 0.9685314685314685, 'recall': 0.8629283489096573, 'F1-score': 0.912685337726524},
 {'accuracy': 0.925,		  'precision': 0.9416058394160584, 'recall': 0.8989547038327527, 'F1-score': 0.9197860962566844}
]
Avg results: 
 {'accuracy': 0.9226666666666666, 'precision': 0.9010014653940962, 'recall': 0.9282869746941402, 'F1-score': 0.912221170354614}




RoBERTa - SwiftKey
-----------------------------------------------------------------------------------------------------------------------------

Linear + RP

Results : [
 {'accuracy': 0.9316666666666666, 'precision': 0.9368932038834952, 'recall': 0.9625935162094763, 'F1-score': 0.9495694956949569},
 {'accuracy': 0.9166666666666666, 'precision': 0.9481132075471698, 'recall': 0.9348837209302325, 'F1-score': 0.9414519906323184},
 {'accuracy': 0.9266666666666666, 'precision': 0.9675925925925926, 'recall': 0.9330357142857143, 'F1-score': 0.9499999999999998},
 {'accuracy': 0.9316666666666666, 'precision': 0.9765807962529274, 'recall': 0.9308035714285714, 'F1-score': 0.9531428571428572},
 {'accuracy': 0.9266666666666666, 'precision': 0.9507042253521126, 'recall': 0.9462616822429907, 'F1-score': 0.9484777517564402}
]
Avg results: 
 {'accuracy': 0.9266666666666665, 'precision': 0.9559768051256595, 'recall': 0.9415156410193971, 'F1-score': 0.9485284190453145}


Linear + RC

Results : [
 {'accuracy': 0.8833333333333333, 'precision': 0.9101941747572816, 'recall': 0.9191176470588235, 'F1-score': 0.9146341463414634},
 {'accuracy': 0.925, 		  'precision': 0.9457547169811321, 'recall': 0.9479905437352246, 'F1-score': 0.9468713105076743},
 {'accuracy': 0.92, 	  	  'precision': 0.9745370370370371, 'recall': 0.9192139737991266, 'F1-score': 0.946067415730337},
 {'accuracy': 0.91, 		  'precision': 0.9695550351288056, 'recall': 0.9098901098901099, 'F1-score': 0.9387755102040816},
 {'accuracy': 0.915, 		  'precision': 0.9107981220657277, 'recall': 0.9675810473815462, 'F1-score': 0.9383313180169287}
]
Avg results: 
 {'accuracy': 0.9106666666666667, 'precision': 0.9421678171939968, 'recall': 0.9327586643729662, 'F1-score': 0.9369359401600971}


MLP + RC

Results : [
 {'accuracy': 0.9316666666666666, 'precision': 0.9368932038834952, 'recall': 0.9625935162094763, 'F1-score': 0.9495694956949569},
 {'accuracy': 0.9233333333333333, 'precision': 0.9433962264150944, 'recall': 0.9478672985781991, 'F1-score': 0.9456264775413711},
 {'accuracy': 0.915,		  'precision': 0.9375, 		   'recall': 0.9440559440559441, 'F1-score': 0.9407665505226481},
 {'accuracy': 0.9316666666666666, 'precision': 0.9461358313817331, 'recall': 0.957345971563981,  'F1-score': 0.9517078916372201},
 {'accuracy': 0.9166666666666666, 'precision': 0.9694835680751174, 'recall': 0.9177777777777778, 'F1-score': 0.9429223744292238}
]
Avg results: 
 {'accuracy': 0.9236666666666666, 'precision': 0.946681765951088, 'recall': 0.9459281016370756, 'F1-score': 0.9461185579650839}


MLP + RP

Results : [`
 {'accuracy': 0.9116666666666666, 'precision': 0.8786407766990292, 'recall': 0.9917808219178083, 'F1-score': 0.931788931788932},
 {'accuracy': 0.9283333333333333, 'precision': 0.9363207547169812, 'recall': 0.9612590799031477, 'F1-score': 0.948626045400239},
 {'accuracy': 0.9183333333333333, 'precision': 0.9166666666666666, 'recall': 0.9682151589242054, 'F1-score': 0.9417360285374554},
 {'accuracy': 0.9116666666666666, 'precision': 0.8899297423887588, 'recall': 0.9844559585492227, 'F1-score': 0.9348093480934808},
 {'accuracy': 0.9133333333333333, 'precision': 0.9272300469483568, 'recall': 0.9495192307692307, 'F1-score': 0.9382422802850356}
]
Avg results: 
 {'accuracy': 0.9166666666666666, 'precision': 0.9097575974839586, 'recall': 0.9710460500127229, 'F1-score': 0.9390405268210286}



BERTtweet - SwiftKey
-------------------------------------------------------------------------------------------------------------------------------


Linear + RP

Results : [
 {'accuracy': 0.8966666666666666, 'precision': 0.8762135922330098, 'recall': 0.9704301075268817, 'F1-score': 0.9209183673469387},
 {'accuracy': 0.93, 'precision': 0.9363207547169812, 'recall': 0.9635922330097088, 'F1-score': 0.9497607655502394},
 {'accuracy': 0.9216666666666666, 'precision': 0.9328703703703703, 'recall': 0.9572446555819477, 'F1-score': 0.9449003516998827},
 {'accuracy': 0.9316666666666666, 'precision': 0.927400468384075, 'recall': 0.9753694581280788, 'F1-score': 0.9507803121248499},
 {'accuracy': 0.9366666666666666, 'precision': 0.9507042253521126, 'recall': 0.9597156398104265, 'F1-score': 0.9551886792452831}
]
Avg results: 
 {'accuracy': 0.9233333333333332, 'precision': 0.9247018822113098, 'recall': 0.9652704188114086, 'F1-score': 0.9443096951934388}


Linear + RC

Results : [
 {'accuracy': 0.93,		  'precision': 0.9490291262135923, 'recall': 0.9490291262135923, 'F1-score': 0.9490291262135923},
 {'accuracy': 0.9316666666666666, 'precision': 0.9669811320754716, 'recall': 0.9382151029748284, 'F1-score': 0.9523809523809523},
 {'accuracy': 0.9216666666666666, 'precision': 0.9444444444444444, 'recall': 0.9466357308584686, 'F1-score': 0.9455388180764773},
 {'accuracy': 0.945, 		  'precision': 0.9648711943793911, 'recall': 0.958139534883721,  'F1-score': 0.9614935822637106},
 {'accuracy': 0.9283333333333333, 'precision': 0.9436619718309859, 'recall': 0.9548693586698337, 'F1-score': 0.949232585596222}
]
Avg results: 
 {'accuracy': 0.9313333333333332, 'precision': 0.9537975737887772, 'recall': 0.9493777707200888, 'F1-score': 0.9515350129061908}


MLP + RC

Results : [
 {'accuracy': 0.9066666666666666, 'precision': 0.9077669902912622, 'recall': 0.9540816326530612, 'F1-score': 0.9303482587064676},
 {'accuracy': 0.9183333333333333, 'precision': 0.9150943396226415, 'recall': 0.9675810473815462, 'F1-score': 0.9406060606060606},
 {'accuracy': 0.9033333333333333, 'precision': 0.9050925925925926, 'recall': 0.9583333333333334, 'F1-score': 0.9309523809523809},
 {'accuracy': 0.91, 		  'precision': 0.8899297423887588, 'recall': 0.9819121447028424, 'F1-score': 0.9336609336609336},
 {'accuracy': 0.7516666666666667, 'precision': 0.9225352112676056, 'recall': 0.7721021611001965, 'F1-score': 0.8406417112299465}
]
Avg results: 
 {'accuracy': 0.8780000000000001, 'precision': 0.9080837752325722, 'recall': 0.9268020638341958, 'F1-score': 0.9152418690311578}


MLP + RP

Results : [
 {'accuracy': 0.9166666666666666, 'precision': 0.9878640776699029, 'recall': 0.9004424778761062, 'F1-score': 0.9421296296296295},
 {'accuracy': 0.9333333333333333, 'precision': 0.9363207547169812, 'recall': 0.9682926829268292, 'F1-score': 0.9520383693045564},
 {'accuracy': 0.9333333333333333, 'precision': 0.9490740740740741, 'recall': 0.9579439252336449, 'F1-score': 0.9534883720930232},
 {'accuracy': 0.9233333333333333, 'precision': 0.936768149882904,  'recall': 0.954653937947494,  'F1-score': 0.9456264775413712},
 {'accuracy': 0.9333333333333333, 'precision': 0.9389671361502347, 'recall': 0.966183574879227,  'F1-score': 0.9523809523809522}
]
Avg results: 
 {'accuracy': 0.9279999999999999, 'precision': 0.9497988384988194, 'recall': 0.9495033197726602, 'F1-score': 0.9491327601899066}




RoBERTa - Tapfish
-------------------------------------------------------------------------------------------------------------------------------------

Linear + RP

Results : [
 {'accuracy': 0.9266666666666666, 'precision': 0.9592760180995475, 'recall': 0.9422222222222222, 'F1-score': 0.9506726457399104},
 {'accuracy': 0.93,	 	  'precision': 0.9324324324324325, 'recall': 0.971830985915493,  'F1-score': 0.9517241379310344},
 {'accuracy': 0.94, 	 	  'precision': 0.9696969696969697, 'recall': 0.9531914893617022, 'F1-score': 0.9613733905579399},
 {'accuracy': 0.915,		  'precision': 0.9025974025974026, 'recall': 0.9858156028368794, 'F1-score': 0.9423728813559322},
 {'accuracy': 0.9283333333333333, 'precision': 0.9201773835920177, 'recall': 0.9834123222748815, 'F1-score': 0.9507445589919816}
]
Avg results: 
 {'accuracy': 0.9280000000000002, 'precision': 0.936836041283674,  'recall': 0.9672945245222356, 'F1-score': 0.9513775229153598}


Linear + RC

Results : [
 {'accuracy': 0.9333333333333333, 'precision': 0.9230769230769231, 'recall': 0.9855072463768116, 'F1-score': 0.9532710280373832},
 {'accuracy': 0.9383333333333334, 'precision': 0.9369369369369369, 'recall': 0.9788235294117648, 'F1-score': 0.9574223245109321},
 {'accuracy': 0.93, 		  'precision': 0.922077922077922,  'recall': 0.9861111111111112, 'F1-score': 0.9530201342281879},
 {'accuracy': 0.9383333333333334, 'precision': 0.935064935064935,  'recall': 0.9840546697038725, 'F1-score': 0.9589345172031077},
 {'accuracy': 0.9333333333333333, 'precision': 0.9379157427937915, 'recall': 0.9724137931034482, 'F1-score': 0.9548532731376974}
]
Avg results: 
 {'accuracy': 0.9346666666666668, 'precision': 0.9310144919901017, 'recall': 0.9813820699414016, 'F1-score': 0.9555002554234617}


MLP + RC

Results : [
 {'accuracy': 0.9266666666666666, 'precision': 0.9502262443438914, 'recall': 0.9502262443438914, 'F1-score': 0.9502262443438914},
 {'accuracy': 0.9433333333333334, 'precision': 0.9572072072072072, 'recall': 0.9659090909090909, 'F1-score': 0.9615384615384616},
 {'accuracy': 0.9483333333333334, 'precision': 0.9502164502164502, 'recall': 0.9821029082774049, 'F1-score': 0.9658965896589659},
 {'accuracy': 0.9166666666666666, 'precision': 0.9069264069264069, 'recall': 0.9835680751173709, 'F1-score': 0.9436936936936936},
 {'accuracy': 0.9316666666666666, 'precision': 0.9334811529933481, 'recall': 0.9745370370370371, 'F1-score': 0.9535673839184597}
]
Avg results: 
 {'accuracy': 0.9333333333333332, 'precision': 0.9396114923374608, 'recall': 0.971268671136959,  'F1-score': 0.9549844746306946}


MLP + RP

Results : [
 {'accuracy': 0.9166666666666666, 'precision': 0.9886877828054299, 'recall': 0.9066390041493776, 'F1-score': 0.945887445887446},
 {'accuracy': 0.875,		  'precision': 0.9887387387387387, 'recall': 0.862475442043222,  'F1-score': 0.9213011542497377},
 {'accuracy': 0.8866666666666667, 'precision': 0.9718614718614719, 'recall': 0.8908730158730159, 'F1-score': 0.9296066252587991},
 {'accuracy': 0.93, 		  'precision': 0.9307359307359307, 'recall': 0.9772727272727273, 'F1-score': 0.9534368070953437},
 {'accuracy': 0.9383333333333334, 'precision': 0.9556541019955654, 'recall': 0.9620535714285714, 'F1-score': 0.9588431590656283}
]
Avg results: 
 {'accuracy': 0.9093333333333333, 'precision': 0.9671356052274274, 'recall': 0.9198627521533828, 'F1-score': 0.9418150383113909}



BERTweet - TapFish
------------------------------------------------------------------------------------------------------------------------------------

Linear + RC




Linear + RP






RoBERTa - Templerun2
------------------------------------------------------------------------------------------------------------------------------------

Linear + RP

Results : [
 {'accuracy': 0.93, 		  'precision': 0.9684466019417476, 'recall': 0.9322429906542056, 'F1-score': 0.9500000000000001},
 {'accuracy': 0.9116666666666666, 'precision': 0.9009433962264151, 'recall': 0.9720101781170484, 'F1-score': 0.9351285189718482},
 {'accuracy': 0.9166666666666666, 'precision': 0.9212962962962963, 'recall': 0.961352657004831,  'F1-score': 0.9408983451536643},
 {'accuracy': 0.905, 		  'precision': 0.9742388758782201, 'recall': 0.9004329004329005, 'F1-score': 0.9358830146231721},
 {'accuracy': 0.9316666666666666, 'precision': 0.9413145539906104, 'recall': 0.9616306954436451, 'F1-score': 0.9513641755634639}
]
Avg results:
 {'accuracy': 0.9189999999999999, 'precision': 0.9412479448666579, 'recall': 0.9455338843305261, 'F1-score': 0.9426548108624297}


Linear + RC

Results : [
 {'accuracy': 0.925, 		  'precision': 0.9733009708737864, 'recall': 0.9218390804597701, 'F1-score': 0.9468713105076741},
 {'accuracy': 0.9266666666666666, 'precision': 0.9245283018867925, 'recall': 0.9702970297029703, 'F1-score': 0.9468599033816426},
 {'accuracy': 0.9216666666666666, 'precision': 0.9259259259259259, 'recall': 0.963855421686747,  'F1-score': 0.9445100354191263},
 {'accuracy': 0.9266666666666666, 'precision': 0.9227166276346604, 'recall': 0.9728395061728395, 'F1-score': 0.9471153846153846},
 {'accuracy': 0.92, 		  'precision': 0.9812206572769953, 'recall': 0.9126637554585153, 'F1-score': 0.9457013574660633}
]
Avg results: 
 {'accuracy': 0.924, 		  'precision': 0.9455384967196322, 'recall': 0.9482989586961684, 'F1-score': 0.9462115982779782}


MLP + RC

Results : [
 {'accuracy': 0.9083333333333333, 'precision': 0.8859223300970874, 'recall': 0.9785522788203753, 'F1-score': 0.9299363057324842},
 {'accuracy': 0.865,		  'precision': 0.964622641509434,  'recall': 0.8610526315789474, 'F1-score': 0.9098998887652948},
 {'accuracy': 0.9066666666666666, 'precision': 0.9212962962962963, 'recall': 0.9476190476190476, 'F1-score': 0.9342723004694835},
 {'accuracy': 0.88, 		  'precision': 0.9859484777517564, 'recall': 0.864476386036961,  'F1-score': 0.9212253829321663},
 {'accuracy': 0.8833333333333333, 'precision': 0.852112676056338,  'recall': 0.981081081081081,  'F1-score': 0.9120603015075377}
]
Avg results: 
 {'accuracy': 0.8886666666666667, 'precision': 0.9219804843421823, 'recall': 0.9265562850272826, 'F1-score': 0.9214788358813933}


MLP + RP

Results : [
 {'accuracy': 0.9116666666666666, 'precision': 0.8907766990291263, 'recall': 0.9786666666666667, 'F1-score': 0.9326556543837358},
 {'accuracy': 0.91,		  'precision': 0.964622641509434,  'recall': 0.9129464285714286, 'F1-score': 0.9380733944954128},
 {'accuracy': 0.92, 		  'precision': 0.9513888888888888, 'recall': 0.9383561643835616, 'F1-score': 0.9448275862068966},
 {'accuracy': 0.905, 		  'precision': 0.9765807962529274, 'recall': 0.8987068965517241, 'F1-score': 0.936026936026936},
 {'accuracy': 0.9483333333333334, 'precision': 0.9647887323943662, 'recall': 0.9625292740046838, 'F1-score': 0.9636576787807738}
]
Avg results: 
 {'accuracy': 0.9189999999999999, 'precision': 0.9496315516149485, 'recall': 0.938241086035613,  'F1-score': 0.9430482499787509}



BERTweet - Templerun2
------------------------------------------------------------------------------------------------------------------------------------

Linear + RP

Results : [
 {'accuracy': 0.9233333333333333, 'precision': 0.9635922330097088, 'recall': 0.927570093457944,  'F1-score': 0.9452380952380951},
 {'accuracy': 0.9266666666666666, 'precision': 0.9599056603773585, 'recall': 0.9377880184331797, 'F1-score': 0.9487179487179488},
 {'accuracy': 0.9333333333333333, 'precision': 0.9444444444444444, 'recall': 0.9622641509433962, 'F1-score': 0.9532710280373831},
 {'accuracy': 0.935, 		  'precision': 0.9297423887587822, 'recall': 0.9778325123152709, 'F1-score': 0.9531812725090038},
 {'accuracy': 0.9233333333333333, 'precision': 0.9624413145539906, 'recall': 0.9318181818181818, 'F1-score': 0.9468822170900693}
]
Avg results: 
 {'accuracy': 0.9283333333333333, 'precision': 0.9520252082288568, 'recall': 0.9474545913935944, 'F1-score': 0.9494581123185}


Linear + RC

Results : [
 {'accuracy': 0.9033333333333333, 'precision': 0.9878640776699029, 'recall': 0.8847826086956522, 'F1-score': 0.9334862385321101},
 {'accuracy': 0.9283333333333333, 'precision': 0.9622641509433962, 'recall': 0.9379310344827586, 'F1-score': 0.9499417927823048},
 {'accuracy': 0.93, 		  'precision': 0.9467592592592593, 'recall': 0.955607476635514,  'F1-score': 0.9511627906976744},
 {'accuracy': 0.94,		  'precision': 0.9625292740046838, 'recall': 0.9535962877030162, 'F1-score': 0.9580419580419581},
 {'accuracy': 0.925,		  'precision': 0.9507042253521126, 'recall': 0.9440559440559441, 'F1-score': 0.9473684210526316}
]
Avg results: 
 {'accuracy': 0.9253333333333333, 'precision': 0.9620241974458711, 'recall': 0.935194670314577,  'F1-score': 0.9480002402213359}


MLP + RC

Results : [
 {'accuracy': 0.9,		  'precision': 0.8737864077669902, 'recall': 0.9782608695652174, 'F1-score': 0.9230769230769229},
 {'accuracy': 0.9266666666666666, 'precision': 0.9363207547169812, 'recall': 0.9589371980676329, 'F1-score': 0.9474940334128878},
 {'accuracy': 0.905,		  'precision': 0.9004629629629629, 'recall': 0.9652605459057072, 'F1-score': 0.9317365269461078},
 {'accuracy': 0.89, 		  'precision': 0.8735362997658079, 'recall': 0.9688311688311688, 'F1-score': 0.9187192118226601},
 {'accuracy': 0.9333333333333333, 'precision': 0.9553990610328639, 'recall': 0.9509345794392523, 'F1-score': 0.9531615925058547}
]
Avg results: 
 {'accuracy': 0.9109999999999999, 'precision': 0.9079010972491212, 'recall': 0.9644448723617958, 'F1-score': 0.9348376575528867}


MLP + RP

Results : [
 {'accuracy': 0.93, 		  'precision': 0.9393203883495146, 'recall': 0.9579207920792079, 'F1-score': 0.9485294117647058},
 {'accuracy': 0.92, 		  'precision': 0.910377358490566,  'recall': 0.9747474747474747, 'F1-score': 0.9414634146341463},
 {'accuracy': 0.9266666666666666, 'precision': 0.9444444444444444, 'recall': 0.9532710280373832, 'F1-score': 0.9488372093023255},
 {'accuracy': 0.9266666666666666, 'precision': 0.9086651053864169, 'recall': 0.9872773536895675, 'F1-score': 0.9463414634146341},
 {'accuracy': 0.9166666666666666, 'precision': 0.9741784037558685, 'recall': 0.9140969162995595, 'F1-score': 0.9431818181818181}
]
Avg results: 
 {'accuracy': 0.924, 'precision': 0.935397140085362, 'recall': 0.9574627129706386, 'F1-score': 0.945670663459526}


--------------------------------------------------------------------------------------------------------------------------------

F1-Score - Facebook
0.884590752, 0.883297085, 0.83597018, 0.930634936, 0.932522285, 0.919247754, 0.923668953, 0.924037952, 0.929665945, 0.926956672, 0.925407177, 0.926820945, 0.91222117

F1-Score - SwiftKey
0.837843509, 0.892874898, 0.909300039, 0.944556143, 0.926956672, 0.93693594, 0.946118558, 0.939040527, 0.948111723, 0.951535013, 0.944309695, 0.915241869, 0.94913276

F1-Score - TapFish


F1-Score - TempleRun2
0.82443696, 0.87920035, 0.882721225, 0.940325431, 0.946211598, 0.942654811, 0.921478836, 0.94304825, 0.951671236, 0.94800024, 0.949458112, 0.934837658, 0.945670663



"GP2-base", "ALBERT-large", "XLNET-base", "RoBERTa-base", "RoBERTa-base + Linear + RC", "RoBERTa-base + Linear + RP", "RoBERTa-base + MLP + RP", "RoBERTa-base + MLP + RC", "BERTweet-base", "BERTweet-base + Linear + RC", "BERTweet-base + Linear + RP", "BERTweet-base + MLP + RP", "BERTweet-base + MLP + RC"

